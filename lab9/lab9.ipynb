{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE 379K: Lab 9\n",
    "\n",
    "## Rohan Nagar and Wenyang Fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohannagar/anaconda/lib/python3.5/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n",
      "/Users/rohannagar/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_file(filename, preds):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('Id,Probability\\n')\n",
    "        for num, pred in zip(range(1,101504), preds):\n",
    "            f.write('{},{}\\n'.format(num, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "One of the features we gave you in the InClass Kaggle competition \n",
    "is a noisy version of another. Specifically, Gaussian iid noise was added.\n",
    "\n",
    "Find these two features and find the mean and variance of the added noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inclass = pd.read_csv('data/train_inclass.csv')\n",
    "test_inclass = pd.read_csv('data/test_inclass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    49998.000000\n",
      "mean         5.272668\n",
      "std        224.530270\n",
      "min         -0.372758\n",
      "25%          0.038775\n",
      "50%          0.186073\n",
      "75%          0.563830\n",
      "max      29110.040580\n",
      "Name: F3, dtype: float64\n",
      "\n",
      "count    49998.000000\n",
      "mean         5.273124\n",
      "std        224.529521\n",
      "min          0.000000\n",
      "25%          0.030389\n",
      "50%          0.154672\n",
      "75%          0.555344\n",
      "max      29110.000000\n",
      "Name: F23, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_inclass['F3'].describe())\n",
    "print()\n",
    "print(train_inclass['F23'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "F3 is a noisy version of F23. F23 corresponds to the feature `RevolvingUtilizationOfUnsecuredLines` in the Loan dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of added noise: 0.07956681166550796\n",
      "Variance of added noise: 0.003602256845676487\n"
     ]
    }
   ],
   "source": [
    "difference = abs(train_inclass['F23'] - train_inclass['F3'])\n",
    "\n",
    "print('Mean of added noise: {}'.format(difference.mean()))\n",
    "print('Variance of added noise: {}'.format(difference.std()**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "As we explained in lecture, the InClass competition data came from \n",
    "https://www.kaggle.com/c/GiveMeSomeCredit\n",
    "\n",
    "You can now double the training data and you have a new validation set using the leaderboard of this Kaggle competition.\n",
    "\n",
    "You can also look at `Data Dictionary.xls` to find what each of the features are exactly.\n",
    "\n",
    "Train your models on the additional data and validate using the private LB of that competition. How do the optimal hyperparameters parameters change? Are the winning XGB parameters still better?\n",
    "\n",
    "Report your Private LB score and include a screenshot of your submissions in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/cs-training.csv', index_col=0)\n",
    "test = pd.read_csv('data/cs-test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop dependent variable in test\n",
    "test = test.drop(['SeriousDlqin2yrs'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill missing with mean\n",
    "train = train.fillna(cs_train.mean())\n",
    "test = test.fillna(cs_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 \n",
    "\n",
    "`Data Dictionary.xls` explains that you are making your decisions on giving loans using the Total balance on credit cards, the Monthly debt payments, the number of mortgage loands of the individual etc. You are now asked to tell a story from this dataset.\n",
    "\n",
    "## Part A\n",
    "\n",
    "Fit a simple logistic regression model and report which features are important (and how they influence the deliquency chance). Discuss what is expected and what is surprising. See how regularization changes the importance of features.\n",
    "\n",
    "Would you expect that the number of dependents to have a postive or negative effect in deliquency probability? Discuss what you think and what the data says."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "Look at your best models (in terms of LB AUC). Try to perform feature interpretability for them. Are the results consistent with interpreting a simple logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "The Age Discrimination in Employment Act (ADEA) forbids age discrimination against people who are age 40 or older, see \n",
    "https://www.eeoc.gov/laws/types/age.cfm\n",
    "\n",
    "Are your models considering age as a factor of influence?\n",
    "\n",
    "Fit a model for people over 40 or 50 and a model for younger people. Are the two models different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split on age\n",
    "train_young = train[train.age <= 40]\n",
    "train_old = train[train.age > 40]\n",
    "\n",
    "test_young = test[test.age <= 40]\n",
    "test_old = test[test.age > 40]\n",
    "\n",
    "# Seperate dependent and independent\n",
    "X_train_young = train_young.drop(['SeriousDlqin2yrs'], axis=1)\n",
    "y_train_young = train_young['SeriousDlqin2yrs']\n",
    "\n",
    "X_train_old = train_old.drop(['SeriousDlqin2yrs'], axis=1)\n",
    "y_train_old = train_old['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80309304  0.80742561  0.80765957  0.81825866  0.81428164  0.80780395\n",
      "  0.81772166  0.81988235  0.80743837  0.80759117]\n",
      "0.811115602013\n"
     ]
    }
   ],
   "source": [
    "# Young model\n",
    "xg = xgb.XGBClassifier(max_depth=8, learning_rate=0.3, n_estimators=155,\n",
    "                       min_child_weight=0.6, subsample=1.0, colsample_bytree=0.45)\n",
    "\n",
    "score = cross_val_score(xg, X=X_train_young, y=y_train_young, scoring='roc_auc', cv=10, n_jobs=-1)\n",
    "print(score)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84839258  0.85353971  0.84613665  0.84599402  0.84436367  0.85257815\n",
      "  0.84813671  0.85349828  0.84802703  0.87025874]\n",
      "0.851092553603\n"
     ]
    }
   ],
   "source": [
    "# Old model\n",
    "xg = xgb.XGBClassifier(max_depth=8, learning_rate=0.3, n_estimators=155,\n",
    "                       min_child_weight=0.6, subsample=1.0, colsample_bytree=0.45)\n",
    "\n",
    "score = cross_val_score(xg, X=X_train_old, y=y_train_old, scoring='roc_auc', cv=10, n_jobs=-1)\n",
    "print(score)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "We can see that a model with the same parameters does much better on the set of older people than on the set of younger people. Age is clearly an influence factor in this dataset. We can use a RandomizedSearch to see if different parameters are selected for models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_cv(model, name):\n",
    "    print(\"Best parameter set found on {} model:\\n\".format(name))\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    for params, mean_score, scores in model.grid_scores_:\n",
    "        print(\"{0:.3f} (+/-{1:.03f}) for {2}\".format(mean_score, scores.std() * 2, params))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set found on young model:\n",
      "\n",
      "{'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.01, 'colsample_bytree': 0.5, 'max_depth': 6}\n",
      "\n",
      "0.837 (+/-0.007) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.01, 'colsample_bytree': 0.5, 'max_depth': 6}\n",
      "0.825 (+/-0.010) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.1, 'colsample_bytree': 0.4, 'max_depth': 8}\n",
      "0.824 (+/-0.009) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.1, 'colsample_bytree': 0.5, 'max_depth': 8}\n",
      "0.836 (+/-0.008) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.01, 'colsample_bytree': 0.4, 'max_depth': 8}\n",
      "0.831 (+/-0.008) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.1, 'colsample_bytree': 0.5, 'max_depth': 6}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohannagar/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:662: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set found on old model:\n",
      "\n",
      "{'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.01, 'colsample_bytree': 0.5, 'max_depth': 8}\n",
      "\n",
      "0.868 (+/-0.010) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.01, 'colsample_bytree': 0.5, 'max_depth': 8}\n",
      "0.863 (+/-0.009) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.1, 'colsample_bytree': 0.4, 'max_depth': 8}\n",
      "0.868 (+/-0.010) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.01, 'colsample_bytree': 0.4, 'max_depth': 6}\n",
      "0.868 (+/-0.009) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.01, 'colsample_bytree': 0.4, 'max_depth': 8}\n",
      "0.866 (+/-0.011) for {'n_estimators': 200, 'min_child_weight': 1.0259783520851542, 'learning_rate': 0.1, 'colsample_bytree': 0.5, 'max_depth': 6}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohannagar/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:662: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [6, 8],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [200],\n",
    "    'min_child_weight': [1/(0.95**(1/2))],\n",
    "    'colsample_bytree': [0.4, 0.5]\n",
    "}\n",
    "\n",
    "xg_clf = RandomizedSearchCV(xgb.XGBClassifier(), parameters, n_iter=5, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "xg_clf.fit(X_train_young, y_train_young)\n",
    "print_cv(xg_clf, 'young')\n",
    "\n",
    "xg_clf = RandomizedSearchCV(xgb.XGBClassifier(), parameters, n_iter=5, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "xg_clf.fit(X_train_old, y_train_old)\n",
    "print_cv(xg_clf, 'old')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Again, we see that when seperated by age, the model with older people performs much better. Also, different paramters are selected. In the younger model, `max_depth` was chosen to be 6, while the older model chose `max_depth` as 8. If we had searched over more parameter values, the models would likely be completely different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "As a law-maker do you think that forcing age and number of dependents to be forbidden features is a good idea for this problem? Try to base your discussion on what you discover from the data.\n",
    "\n",
    "## Answer\n",
    "\n",
    "I think that from a law point of view, those features should be forbidden no matter what the data says. Age should not be considered when deciding if a person can get a loan or not, because that does classify as age discrimination. Also, if we are to not discriminate for people 40 or older, we should not discriminate based on any age value.\n",
    "\n",
    "According to the data, knowing the age can be valuable in predicting financial distress. This is clear from the work we did in part A. Since there is such a boost in performace for a model predicting on only people over the age of 40, this means that using their age is very helpful to the model. This may seem like a good idea since we get a better AUC ROC score, but in fact this is leading to age discrimination. As a law-maker, I would not feel comfortable knowing that we can predict so much better for people over age 40. This may be generalization and can lead to discrimination based on a person's age.\n",
    "\n",
    "Because of this, I think that it would be a good idea (as a law-maker) to make age and the number of dependents to be forbidden features. However, from a data perspective (disregarding law), knowing the age can help your models a lot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
