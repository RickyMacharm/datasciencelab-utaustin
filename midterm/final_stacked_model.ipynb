{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohannagar/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feature(X, name, values):\n",
    "        X_new = X\n",
    "        X_new[name] = values\n",
    "        \n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackedEnsemble():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logistic_regr = LogisticRegression(C=0.1, penalty='l1')\n",
    "        self.adaboost = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1)\n",
    "        self.random_forest = RandomForestClassifier(n_estimators=2000, criterion='entropy', max_features='auto', bootstrap=True)\n",
    "        self.xgb = xgb.XGBClassifier(max_depth=4, learning_rate=0.01, n_estimators=1000)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.logistic_regr.fit(X, y)\n",
    "        preds = self.logistic_regr.predict_proba(X)[:, 1]\n",
    "        X = add_feature(X, 'lg', preds)\n",
    "\n",
    "        self.adaboost.fit(X, y)\n",
    "        preds = self.adaboost.predict_proba(X)[:, 1]\n",
    "        X = add_feature(X, 'ab', preds)\n",
    "        \n",
    "        self.random_forest.fit(X, y)\n",
    "        preds = self.random_forest.predict_proba(X)[:, 1]\n",
    "        X = add_feature(X, 'rf', preds)\n",
    "        \n",
    "        self.xgb.fit(X, y)\n",
    "        \n",
    "        \n",
    "    def predict_proba(self, X_test):\n",
    "        preds = self.logistic_regr.predict_proba(X_test)[:, 1]\n",
    "        X_test = add_feature(X_test, 'lg', preds)\n",
    "        \n",
    "        preds = self.adaboost.predict_proba(X_test)[:, 1]\n",
    "        X_test = add_feature(X_test, 'ab', preds)\n",
    "        \n",
    "        preds = self.random_forest.predict_proba(X_test)[:, 1]\n",
    "        X_test = add_feature(X_test, 'rf', preds)\n",
    "        \n",
    "        return self.xgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_file(filename, ids, preds):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('id,Y\\n')\n",
    "        for num, pred in zip(ids, preds):\n",
    "            f.write('{},{}\\n'.format(num, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill NA values with the mean\n",
    "train = train.fillna(train.mean())\n",
    "test = test.fillna(train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'Y'], axis=1)\n",
    "y_train = train['Y']\n",
    "\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop highly correlated features\n",
    "X_train = X_train.drop(['F18', 'F3'], axis=1)\n",
    "X_test = X_test.drop(['F18', 'F3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ens = StackedEnsemble()\n",
    "ens.fit(X_train, y_train)\n",
    "preds = ens.predict_proba(X_test)\n",
    "to_file('submissions/stacked_clean.csv', ids, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
